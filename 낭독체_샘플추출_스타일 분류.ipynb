{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['낭독체_01.csv',\n",
       " '낭독체_02.csv',\n",
       " '낭독체_03.csv',\n",
       " '낭독체_04.csv',\n",
       " '낭독체_05.csv',\n",
       " '낭독체_06.csv',\n",
       " '낭독체_07.csv',\n",
       " '낭독체_08.csv',\n",
       " '낭독체_09.csv',\n",
       " '낭독체_10.csv',\n",
       " '낭독체_11.csv',\n",
       " '낭독체_12.csv',\n",
       " '낭독체_13.csv',\n",
       " '낭독체_14.csv',\n",
       " '낭독체_15.csv',\n",
       " '낭독체_16.csv',\n",
       " '낭독체_17.csv',\n",
       " '낭독체_18.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = listdir('./낭독체_편집/csv')\n",
    "print(len(csv_files))\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:24<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "script_total = []\n",
    "\n",
    "for i in tqdm(csv_files, mininterval=1):\n",
    "    f = open(\"./낭독체_편집/csv/\"+i, 'r', encoding='utf-8-sig')\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        script_total.append(line.strip('\\n'))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17027769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'우리 국민의 일인당 소득은 북한의 열세배 국민총소득은 스물다섯배라고 합니다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(script_total))\n",
    "script_total[17026347]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    pattern = '[一-龥]'\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '([a-zA-Z0-9]+\\s\\.html프린트\\s하시려면)'\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '(^[0-9]\\.)'\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '([0-9]\\.$)'\n",
    "    text = re.sub(pattern=pattern, repl='.', string=text)\n",
    "    pattern = '[\"]'\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '^[.,]'\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 17027769/17027769 [03:16<00:00, 86761.82it/s]\n"
     ]
    }
   ],
   "source": [
    "clear_li = []\n",
    "\n",
    "for i in tqdm(script_total, mininterval=1):\n",
    "    clear = clean_text(i)\n",
    "    clear_li.append(clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 국민의 일인당 소득은 북한의 열세배 국민총소득은 스물다섯배라고 합니다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_li[17026347]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_df = pd.DataFrame(clear_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_df[0].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13418302</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418370</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13419692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13423362</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13423372</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13739492</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13741134</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13747060</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13747071</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13750246</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "13418302  NaN\n",
       "13418370  NaN\n",
       "13419692  NaN\n",
       "13423362  NaN\n",
       "13423372  NaN\n",
       "...       ...\n",
       "13739492  NaN\n",
       "13741134  NaN\n",
       "13747060  NaN\n",
       "13747071  NaN\n",
       "13750246  NaN\n",
       "\n",
       "[111 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_df[clear_df[0].isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17027658\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>새천년 이 아침</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>한반도의 모든 산들이 어기영차 치달아 오르고, 만주벌 대륙의 산들이 쉼없이 내려와,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>새 하늘 길을 열었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>천지를 둘러싼 저 용틀임. 저 피와 땀과 눈물의 용틀임. 마침내 대지의 젖,가슴 시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                           새천년 이 아침\n",
       "1  한반도의 모든 산들이 어기영차 치달아 오르고, 만주벌 대륙의 산들이 쉼없이 내려와,...\n",
       "2                                       새 하늘 길을 열었다.\n",
       "3  천지를 둘러싼 저 용틀임. 저 피와 땀과 눈물의 용틀임. 마침내 대지의 젖,가슴 시...\n",
       "4  모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_drop = clear_df.dropna(axis=0)\n",
    "print(len(clear_drop))\n",
    "clear_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_total_sample = clear_drop[0].sample(n=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(script_total_sample))\n",
    "script_total_sample_sort = script_total_sample.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_sample_df = pd.DataFrame(script_total_sample_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_drop.to_pickle(\"./script_낭독체.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_sample_df.to_csv(\"./script_sample_1000_4.csv\", encoding='utf-8-sig', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장스타일 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_pickle(\"./낭독체_편집/script_낭독체.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ser = text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_li = text_ser.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['새천년 이 아침',\n",
       " '한반도의 모든 산들이 어기영차 치달아 오르고, 만주벌 대륙의 산들이 쉼없이 내려와, 보라! 여기 백두의 하늘 연못. 새 천년 우주의 꿈을 품었다.',\n",
       " '새 하늘 길을 열었다.',\n",
       " '천지를 둘러싼 저 용틀임. 저 피와 땀과 눈물의 용틀임. 마침내 대지의 젖,가슴 시린 맑은 물 하늘에 바쳤나니, 천지는 명령한다.',\n",
       " '모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것들이 흔적도 없이 사라진 새 세상에 오라. 헌신.긍지.사랑.희망.승리.화해.통일이여 춤추며 박수치며 오라.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_li[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하네.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text = '개미는 오늘도 열심히 일을 하네.'\n",
    "#sp = text.split()\n",
    "#sp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt_10 = text_li[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt_end = []\n",
    "\n",
    "#for d in txt_10:\n",
    "    #word = d.split()[-1]\n",
    "    #txt_end.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 17027658/17027658 [00:26<00:00, 651175.29it/s]\n"
     ]
    }
   ],
   "source": [
    "#end_li = []\n",
    "\n",
    "#for i in tqdm(text_li, mininterval=1):\n",
    "    #end = i.split()[-1]\n",
    "    #end_li.append(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17027658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['아침', '품었다.', '열었다.', '명령한다.', '오라.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(len(end_li))\n",
    "#end_li[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from konlpy.tag import Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reijin1105\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('달라지', 'VV'), ('었', 'EP'), ('다', 'EF'), ('.', 'SF')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Komoran().pos(end_li[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex_li = ['먹었습니다.','합니다.','있어요','했어요.','가요.','한다.','이다.']\n",
    "#ser = pd.Series(ex_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     있어요\n",
       "3    했어요.\n",
       "4     가요.\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ser[ser.str.endswith(('요','요.'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'니다\\.?$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1 :  <re.Match object; span=(3, 6), match='니다.'>\n",
      "m1 :  <re.Match object; span=(2, 5), match='니다.'>\n",
      "m1 :  None\n",
      "m1 :  None\n"
     ]
    }
   ],
   "source": [
    "#txt = ['있었습니다.','아닙니다.','반말이야.','이름이 뭐니?']\n",
    "\n",
    "#for t in txt:\n",
    "    #m1 = re.search('니다\\.?$', t)\n",
    "    #print(\"m1 : \", m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_list=[]\n",
    "#b_list=[]\n",
    "\n",
    "#for i in txt:\n",
    "    #j = re.search('니다\\.$', i)\n",
    "    #if j == None:\n",
    "        #b_list.append(i)\n",
    "    #else:\n",
    "        #a_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['있었습니다.', '아닙니다.']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['반말이야.', '이름이 뭐니?']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 17027658/17027658 [00:39<00:00, 431314.96it/s]\n"
     ]
    }
   ],
   "source": [
    "hapsho_list = []\n",
    "no_hapsho_list = []\n",
    "\n",
    "for i in tqdm(text_li, mininterval=1):\n",
    "    end = i.split()[-1]\n",
    "    j = re.search('니다\\.?$', end)\n",
    "    if j == None:\n",
    "        no_hapsho_list.append(i)\n",
    "    else:\n",
    "        hapsho_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5273123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['21세기와 새 밀레니엄은 엄밀히 말해 서기 2001년부터입니다.',\n",
       " '서 예수가 태어난 해를 AD1년으로 규정했기 때문입니다.',\n",
       " '따라서 AD 1세기는 1년에서 100년까지이며, 20세기도 1901년에서 2000년까지입니다.',\n",
       " '또 첫 밀레니엄은 서기 1000년까지, 두번째 밀레니엄은 2000년까지입니다.',\n",
       " '그러나 2000이라는 숫자가 주는 시대적 체감 이 워낙 크기 때문에 이를 감안해 지면을 제작했음을 양지하시기 바랍니다.']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(hapsho_list))\n",
    "hapsho_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5273123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['21세기와 새 밀레니엄은 엄밀히 말해 서기 2001년부터입니다.',\n",
       " '서 예수가 태어난 해를 AD1년으로 규정했기 때문입니다.',\n",
       " '따라서 AD 1세기는 1년에서 100년까지이며, 20세기도 1901년에서 2000년까지입니다.',\n",
       " '또 첫 밀레니엄은 서기 1000년까지, 두번째 밀레니엄은 2000년까지입니다.',\n",
       " '그러나 2000이라는 숫자가 주는 시대적 체감 이 워낙 크기 때문에 이를 감안해 지면을 제작했음을 양지하시기 바랍니다.']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(hapsho_list))\n",
    "hapsho_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./hapsho_li.pkl', 'wb') as f:\n",
    "    pickle.dump(hapsho_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "hapsho_df = pd.DataFrame(hapsho_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "hapsho_df.to_csv(\"./합쇼체.txt\", encoding='utf-8-sig', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플\n",
    "#hapsho_sample = hapsho_df.sample(n=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#print(len(hapsho_sample))\n",
    "#hapsho_sample_sort = hapsho_sample.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hapsho_sample_sort.to_csv(\"./합쇼체_sample.csv\", encoding='utf-8-sig', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11754535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['새천년 이 아침',\n",
       " '한반도의 모든 산들이 어기영차 치달아 오르고, 만주벌 대륙의 산들이 쉼없이 내려와, 보라! 여기 백두의 하늘 연못. 새 천년 우주의 꿈을 품었다.',\n",
       " '새 하늘 길을 열었다.',\n",
       " '천지를 둘러싼 저 용틀임. 저 피와 땀과 눈물의 용틀임. 마침내 대지의 젖,가슴 시린 맑은 물 하늘에 바쳤나니, 천지는 명령한다.',\n",
       " '모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것들이 흔적도 없이 사라진 새 세상에 오라. 헌신.긍지.사랑.희망.승리.화해.통일이여 춤추며 박수치며 오라.']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(no_hapsho_list))\n",
    "no_hapsho_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5273123\n",
      "11754535\n",
      "17027658\n"
     ]
    }
   ],
   "source": [
    "print(len(hapsho_list))\n",
    "print(len(no_hapsho_list))\n",
    "print(len(hapsho_list)+len(no_hapsho_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 11754535/11754535 [00:44<00:00, 263519.04it/s]\n"
     ]
    }
   ],
   "source": [
    "yo_list = []\n",
    "no_yo_list = []\n",
    "\n",
    "for i in tqdm(no_hapsho_list, mininterval=1):\n",
    "    end = i.split()[-1]\n",
    "    j = re.search('요\\.?$', end)\n",
    "    if j == None:\n",
    "        no_yo_list.append(i)\n",
    "    else:\n",
    "        yo_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1990년대의 경험으로 2050년의 세계를 그릴 수 있을지도 모르지요.',\n",
       " '김아시아 지역공동체는 어떤 성격의 것일까요.',\n",
       " '전전 교토학파의 아시아의 공생공영의 이념과 비슷하지 않을까요.',\n",
       " '종교가 아니라 윤리가 21세기의 가장 큰 문제라고 생각해요.',\n",
       " '전쟁 포기의 이념은 칸트에서 나왔지만 서양에서는 실현되지 않았어요. 일본 헌법을 만든 미국인들은 그 이념을 일본에서 실현하려고 했던 것 같아요. 이런 일에 이번에는 일본이 선두에 섰으면 좋겠지만 분위기가 변했어요.']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(yo_list))\n",
    "yo_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo_df = pd.DataFrame(yo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플\n",
    "#yo_sample = yo_df.sample(n=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#print(len(yo_sample))\n",
    "#yo_sample_sort = yo_sample.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo_df.to_csv(\"./해요체.txt\", encoding='utf-8-sig', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11467417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['새천년 이 아침',\n",
       " '한반도의 모든 산들이 어기영차 치달아 오르고, 만주벌 대륙의 산들이 쉼없이 내려와, 보라! 여기 백두의 하늘 연못. 새 천년 우주의 꿈을 품었다.',\n",
       " '새 하늘 길을 열었다.',\n",
       " '천지를 둘러싼 저 용틀임. 저 피와 땀과 눈물의 용틀임. 마침내 대지의 젖,가슴 시린 맑은 물 하늘에 바쳤나니, 천지는 명령한다.',\n",
       " '모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것들이 흔적도 없이 사라진 새 세상에 오라. 헌신.긍지.사랑.희망.승리.화해.통일이여 춤추며 박수치며 오라.']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(no_yo_list))\n",
    "no_yo_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287118\n",
      "11467417\n",
      "11754535\n"
     ]
    }
   ],
   "source": [
    "print(len(yo_list))\n",
    "print(len(no_yo_list))\n",
    "print(len(yo_list)+len(no_yo_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 11467417/11467417 [00:55<00:00, 207413.78it/s]\n"
     ]
    }
   ],
   "source": [
    "nor_list = []\n",
    "que_list = []\n",
    "\n",
    "for i in tqdm(no_yo_list, mininterval=1):\n",
    "    end = i.split()[-1]\n",
    "    j = re.search('\\?$', end)\n",
    "    if j == None:\n",
    "        nor_list.append(i)\n",
    "    else:\n",
    "        que_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['헬로 2000 컴퓨터를 입는다?',\n",
       " '생각하기도 전에 눈물이 되곤 하는 어머니 김정자 여사, 지난해 성탄절 전야에 흙으로 돌아가신 존경하는 아버지, 묵묵히 지켜 봐준 사랑하는 핏줄들, 한시름 놓으셨죠?',\n",
       " '그는 냉장고에서 물병을 꺼내 컵과 함께 가지고 왔다.컵에 물을 따르며 그는 말을 이었다. 그녀는 이곳에 머물고 싶다고 나에게 말했습니다.우리는 자주 주변을 산책하게 되었지요.그녀는 걷는 것을 좋아했습니다.몸이 아주 가뿐해지고 있었으니까요.그때까지만 해도 그녀의 마음은 평온한 편이었습니다.자신이 건반조차 제대로 두드릴 수 없다는 사실을 깨닫는 그 순간까지는 말입니다.어느 날 그녀는 피아노를 연주하다 말고 나를 돌아보았습니다.불규칙한 건반 음이 한번 울리고 난 다음이었지요.그녀의 새끼손가락 하나가 부러져 건반 위에 놓여 있었습니다.나는 상심한 그녀에게 모차르트를 연주해주었습니다.날이 갈수록 그녀의 몸은 점점 가벼워졌습니다.사뿐사뿐 날듯이 걸어다녔지요.새의 깃대처럼,그녀의 뼛속은 텅 비어 있는 듯했습니다.그러나 바람이 조금만 세게 불어도 깨져버릴 것처럼 그녀는 늘 위태로웠습니다.우리는 결국 산책마저 단념해야 했습니다.그 이후로는 목욕을 해도 그녀의 피부는 부드러워지지 않았습니다.이해되십니까?',\n",
       " '취재일기 Y2K 사기극이었나?',\n",
       " '2000년 서울 시정의 방향은?']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(que_list))\n",
    "que_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_df = pd.DataFrame(que_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플\n",
    "#que_sample = que_df.sample(n=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#print(len(que_sample))\n",
    "#que_sample_sort = que_sample.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_df.to_csv(\"./의문문.txt\", encoding='utf-8-sig', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11357982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['새천년 이 아침',\n",
       " '한반도의 모든 산들이 어기영차 치달아 오르고, 만주벌 대륙의 산들이 쉼없이 내려와, 보라! 여기 백두의 하늘 연못. 새 천년 우주의 꿈을 품었다.',\n",
       " '새 하늘 길을 열었다.',\n",
       " '천지를 둘러싼 저 용틀임. 저 피와 땀과 눈물의 용틀임. 마침내 대지의 젖,가슴 시린 맑은 물 하늘에 바쳤나니, 천지는 명령한다.',\n",
       " '모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것들이 흔적도 없이 사라진 새 세상에 오라. 헌신.긍지.사랑.희망.승리.화해.통일이여 춤추며 박수치며 오라.']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(nor_list))\n",
    "nor_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109435\n",
      "11357982\n",
      "11467417\n"
     ]
    }
   ],
   "source": [
    "print(len(que_list))\n",
    "print(len(nor_list))\n",
    "print(len(que_list)+len(nor_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 11357982/11357982 [00:32<00:00, 344935.36it/s]\n"
     ]
    }
   ],
   "source": [
    "da_list = []\n",
    "no_da_list = []\n",
    "\n",
    "for i in tqdm(nor_list, mininterval=1):\n",
    "    end = i.split()[-1]\n",
    "    j = re.search('다\\.$', end)\n",
    "    if j == None:\n",
    "        no_da_list.append(i)\n",
    "    else:\n",
    "        da_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9164402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['한반도의 모든 산들이 어기영차 치달아 오르고, 만주벌 대륙의 산들이 쉼없이 내려와, 보라! 여기 백두의 하늘 연못. 새 천년 우주의 꿈을 품었다.',\n",
       " '새 하늘 길을 열었다.',\n",
       " '천지를 둘러싼 저 용틀임. 저 피와 땀과 눈물의 용틀임. 마침내 대지의 젖,가슴 시린 맑은 물 하늘에 바쳤나니, 천지는 명령한다.',\n",
       " '우리는 달라졌다.',\n",
       " '우리는 깨어났다.']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(da_list))\n",
    "da_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['새천년 이 아침',\n",
       " '모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것들이 흔적도 없이 사라진 새 세상에 오라. 헌신.긍지.사랑.희망.승리.화해.통일이여 춤추며 박수치며 오라.',\n",
       " '새로운 정신, 새로운 지식, 빛의 네트워크로 하나된 우리. 천지여, 신인류의 정수리에 푸르고 푸른 기운이 샘솟게 하라.',\n",
       " '둥, 둥, 둥. 천년의 아침을 알리는 저 북소리. 나가라. 뛰어라. 솟아오르라.',\n",
       " '지지정당 없다 69.9 본사 여론조사']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(no_da_list))\n",
    "no_da_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9164402\n",
      "2193580\n",
      "11357982\n"
     ]
    }
   ],
   "source": [
    "print(len(da_list))\n",
    "print(len(no_da_list))\n",
    "print(len(da_list)+len(no_da_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반말(~다.) 리스트 피클 저장\n",
    "import pickle\n",
    "\n",
    "with open('./da_list.pkl', 'wb') as f:\n",
    "    pickle.dump(da_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_da_list 저장\n",
    "with open('./no_da_list.pkl', 'wb') as f:\n",
    "    pickle.dump(no_da_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 반말과 독백, 그리고 명사를 나눠야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 2193580/2193580 [00:11<00:00, 188085.51it/s]\n"
     ]
    }
   ],
   "source": [
    "end_li = []\n",
    "\n",
    "for i in tqdm(no_da_list, mininterval=1):\n",
    "    end = i.split()[-1]\n",
    "    end_li.append(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아침', '오라.', '하라.', '솟아오르라.', '여론조사']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_li[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./da_list.pkl', 'wb') as f:\n",
    "    pickle.dump(da_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reijin1105\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "#from konlpy.tag import Komoran\n",
    "from konlpy.tag import Kkma \n",
    "kkma = Kkma()\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eomi_li = []\n",
    "\n",
    "for i in tqdm(end_li, mininterval=1):\n",
    "    eomi = kkma.pos(i)\n",
    "    eomi_li.append(eomi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소 분석기로 어미만 모은 피클 파일 \n",
    "with open('./eomi_li.pkl', 'wb') as f:\n",
    "    pickle.dump(eomi_li, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어미 리스트 피클 파일 읽기\n",
    "with open('./eomi_li.pkl', 'rb') as f:\n",
    "    eomi_li = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNG'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eomi_li[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_li[217436]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'신발을 벗고 가방을 베개삼아 눕자 하늘이 보인다. 등나무 덩굴을 얹어놓은 정자 지붕 틈새로 보이는 하늘.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_da_list[217436]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['새천년 이 아침',\n",
       " '모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것들이 흔적도 없이 사라진 새 세상에 오라. 헌신.긍지.사랑.희망.승리.화해.통일이여 춤추며 박수치며 오라.',\n",
       " '새로운 정신, 새로운 지식, 빛의 네트워크로 하나된 우리. 천지여, 신인류의 정수리에 푸르고 푸른 기운이 샘솟게 하라.',\n",
       " '둥, 둥, 둥. 천년의 아침을 알리는 저 북소리. 나가라. 뛰어라. 솟아오르라.',\n",
       " '지지정당 없다 69.9 본사 여론조사']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_da_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아침', '오라.', '하라.', '솟아오르라.', '여론조사']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_li[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a_index = []\n",
    "\n",
    "for i in eomi_li[:5]:\n",
    "    j = i[-2:]\n",
    "    k = eomi_li.index(i)\n",
    "    a.append(j)\n",
    "    a_index.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('아침', 'NNG')],\n",
       " [('라', 'ECD'), ('.', 'SF')],\n",
       " [('라', 'ECD'), ('.', 'SF')],\n",
       " [('라', 'ECD'), ('.', 'SF')],\n",
       " [('여론', 'NNG'), ('조사', 'NNG')]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('아침', 'NNG')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('.', 'SF')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eomi_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eomi_li_1 = eomi_li[:500000]\n",
    "eomi_li_2 = eomi_li[500000:1000000]\n",
    "eomi_li_3 = eomi_li[1000000:1500000]\n",
    "eomi_li_4 = eomi_li[1500000:2000000]\n",
    "eomi_li_5 = eomi_li[2000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./eomi_li_1.pkl', 'wb') as f:\n",
    "    pickle.dump(eomi_li_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./eomi_li_2.pkl', 'wb') as f:\n",
    "    pickle.dump(eomi_li_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./eomi_li_3.pkl', 'wb') as f:\n",
    "    pickle.dump(eomi_li_3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./eomi_li_4.pkl', 'wb') as f:\n",
    "    pickle.dump(eomi_li_4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./eomi_li_5.pkl', 'wb') as f:\n",
    "    pickle.dump(eomi_li_5, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트 피클 파일 읽기\n",
    "with open('./eomi_li_.pkl', 'rb') as f:\n",
    "    eomi_li_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./eomi_li_2.pkl', 'rb') as f:\n",
    "    eomi_li_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./eomi_li_3.pkl', 'rb') as f:\n",
    "    eomi_li_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./eomi_li_4.pkl', 'rb') as f:\n",
    "    eomi_li_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./eomi_li_5.pkl', 'rb') as f:\n",
    "    eomi_li_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('아침', 'NNG')],\n",
       " [('오', 'VV'), ('라', 'ECD'), ('.', 'SF')],\n",
       " [('하', 'VV'), ('라', 'ECD'), ('.', 'SF')],\n",
       " [('솟아오르', 'VV'), ('라', 'ECD'), ('.', 'SF')],\n",
       " [('여론', 'NNG'), ('조사', 'NNG')]]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(eomi_li))\n",
    "eomi_li[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 2193580/2193580 [00:02<00:00, 876636.69it/s]\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "\n",
    "for i in tqdm(eomi_li, mininterval=1):\n",
    "    if len(i) == 1:\n",
    "        j = i\n",
    "        k = 'noun'\n",
    "        l = 'not_noun'\n",
    "        if j[0][1] == 'NNG':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NNP':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NNB':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NNM':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NR':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NP':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'ETN':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'XSN':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        else:\n",
    "            #b_li.append(i)\n",
    "            n.append(l)\n",
    "    else :\n",
    "        j = i[-2:]\n",
    "        k = 'noun'\n",
    "        l = 'not_noun'\n",
    "        if j[1][1] == 'NNG':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[1][1] == 'NNP':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[1][1] == 'NNB':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[1][1] == 'NNM':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[1][1] == 'NR':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[1][1] == 'NP':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[1][1] == 'ETN':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[1][1] == 'XSN':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NNG' and j[1][1] == 'SF':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NNP' and j[1][1] == 'SF':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NNB' and j[1][1] == 'SF':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NNM' and j[1][1] == 'SF':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NR' and j[1][1] == 'SF':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'NP' and j[1][1] == 'SF':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'ETN' and j[1][1] == 'SF':\n",
    "            #a_li.append(i)\n",
    "            n.append(k)\n",
    "        elif j[0][1] == 'XSN' and j[1][1] == 'SF':\n",
    "            #a_li.append(i)   \n",
    "            n.append(k)\n",
    "        else:\n",
    "            #b_li.append(i)\n",
    "            n.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./da_list.pkl', 'rb') as f:\n",
    "    da_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9164402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['한반도의 모든 산들이 어기영차 치달아 오르고, 만주벌 대륙의 산들이 쉼없이 내려와, 보라! 여기 백두의 하늘 연못. 새 천년 우주의 꿈을 품었다.',\n",
       " '새 하늘 길을 열었다.',\n",
       " '천지를 둘러싼 저 용틀임. 저 피와 땀과 눈물의 용틀임. 마침내 대지의 젖,가슴 시린 맑은 물 하늘에 바쳤나니, 천지는 명령한다.',\n",
       " '우리는 달라졌다.',\n",
       " '우리는 깨어났다.']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(da_list))\n",
    "da_list[:5]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./no_da_list.pkl', 'rb') as f:\n",
    "    no_da_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['새천년 이 아침',\n",
       " '모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것들이 흔적도 없이 사라진 새 세상에 오라. 헌신.긍지.사랑.희망.승리.화해.통일이여 춤추며 박수치며 오라.',\n",
       " '새로운 정신, 새로운 지식, 빛의 네트워크로 하나된 우리. 천지여, 신인류의 정수리에 푸르고 푸른 기운이 샘솟게 하라.',\n",
       " '둥, 둥, 둥. 천년의 아침을 알리는 저 북소리. 나가라. 뛰어라. 솟아오르라.',\n",
       " '지지정당 없다 69.9 본사 여론조사']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(no_da_list))\n",
    "no_da_list[:5]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['noun',\n",
       " 'not_noun',\n",
       " 'not_noun',\n",
       " 'not_noun',\n",
       " 'noun',\n",
       " 'noun',\n",
       " 'noun',\n",
       " 'noun',\n",
       " 'noun',\n",
       " 'not_noun']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(n))\n",
    "n[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./n_li.pkl', 'wb') as f:\n",
    "    pickle.dump(n, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('./a_index_li_5.pkl', 'wb') as f:\n",
    "    #pickle.dump(a_index_li, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('./b_index_li_5.pkl', 'wb') as f:\n",
    "    #pickle.dump(b_index_li, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#명사형 리스트 읽기 \n",
    "with open('./a_index_li_5.pkl', 'rb') as f:\n",
    "    noun_idx_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#비명사형 리스트 읽기 \n",
    "with open('./b_index_li_5.pkl', 'rb') as f:\n",
    "    not_noun_idx_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_da_df = pd.DataFrame(no_da_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>새천년 이 아침</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>새로운 정신, 새로운 지식, 빛의 네트워크로 하나된 우리. 천지여, 신인류의 정수리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>둥, 둥, 둥. 천년의 아침을 알리는 저 북소리. 나가라. 뛰어라. 솟아오르라.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>지지정당 없다 69.9 본사 여론조사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>김행 전문기자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>이회창 총재 신년사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>박태준 총재 신년사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>이만섭 대행 신년사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>김대중 대통령 신년사 21세기 한민족의 시대로</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                           새천년 이 아침\n",
       "1  모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것...\n",
       "2  새로운 정신, 새로운 지식, 빛의 네트워크로 하나된 우리. 천지여, 신인류의 정수리...\n",
       "3       둥, 둥, 둥. 천년의 아침을 알리는 저 북소리. 나가라. 뛰어라. 솟아오르라.\n",
       "4                               지지정당 없다 69.9 본사 여론조사\n",
       "5                                            김행 전문기자\n",
       "6                                         이회창 총재 신년사\n",
       "7                                         박태준 총재 신년사\n",
       "8                                         이만섭 대행 신년사\n",
       "9                          김대중 대통령 신년사 21세기 한민족의 시대로"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(no_da_df))\n",
    "no_da_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = pd.DataFrame(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0      noun\n",
       "1  not_noun\n",
       "2  not_noun\n",
       "3  not_noun\n",
       "4      noun\n",
       "5      noun\n",
       "6      noun\n",
       "7      noun\n",
       "8      noun\n",
       "9  not_noun"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(n_df))\n",
    "n_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_da_n_df = pd.concat([no_da_df, n_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>새천년 이 아침</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것...</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>새로운 정신, 새로운 지식, 빛의 네트워크로 하나된 우리. 천지여, 신인류의 정수리...</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>둥, 둥, 둥. 천년의 아침을 알리는 저 북소리. 나가라. 뛰어라. 솟아오르라.</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>지지정당 없다 69.9 본사 여론조사</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         0\n",
       "0                                           새천년 이 아침      noun\n",
       "1  모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것...  not_noun\n",
       "2  새로운 정신, 새로운 지식, 빛의 네트워크로 하나된 우리. 천지여, 신인류의 정수리...  not_noun\n",
       "3       둥, 둥, 둥. 천년의 아침을 알리는 저 북소리. 나가라. 뛰어라. 솟아오르라.  not_noun\n",
       "4                               지지정당 없다 69.9 본사 여론조사      noun"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(no_da_n_df))\n",
    "no_da_n_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./no_da_noun_df.pkl', 'wb') as f:\n",
    "    pickle.dump(no_da_n_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 피클파일 불러서 계속 작업하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./no_da_noun_df.pkl', 'rb') as f:\n",
    "    no_da_n_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utter</th>\n",
       "      <th>noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>새천년 이 아침</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것...</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>새로운 정신, 새로운 지식, 빛의 네트워크로 하나된 우리. 천지여, 신인류의 정수리...</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>둥, 둥, 둥. 천년의 아침을 알리는 저 북소리. 나가라. 뛰어라. 솟아오르라.</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>지지정당 없다 69.9 본사 여론조사</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>김행 전문기자</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>이회창 총재 신년사</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>박태준 총재 신년사</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>이만섭 대행 신년사</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>김대중 대통령 신년사 21세기 한민족의 시대로</td>\n",
       "      <td>not_noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               utter      noun\n",
       "0                                           새천년 이 아침      noun\n",
       "1  모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것...  not_noun\n",
       "2  새로운 정신, 새로운 지식, 빛의 네트워크로 하나된 우리. 천지여, 신인류의 정수리...  not_noun\n",
       "3       둥, 둥, 둥. 천년의 아침을 알리는 저 북소리. 나가라. 뛰어라. 솟아오르라.  not_noun\n",
       "4                               지지정당 없다 69.9 본사 여론조사      noun\n",
       "5                                            김행 전문기자      noun\n",
       "6                                         이회창 총재 신년사      noun\n",
       "7                                         박태준 총재 신년사      noun\n",
       "8                                         이만섭 대행 신년사      noun\n",
       "9                          김대중 대통령 신년사 21세기 한민족의 시대로  not_noun"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(no_da_n_df))\n",
    "no_da_n_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_da_n_df.columns = [\"utter\", \"noun\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                새천년 이 아침\n",
       "4                                    지지정당 없다 69.9 본사 여론조사\n",
       "5                                                 김행 전문기자\n",
       "6                                              이회창 총재 신년사\n",
       "7                                              박태준 총재 신년사\n",
       "                                ...                      \n",
       "2193573            기자 담배 끊기를 결심하기에 앞서 자신이 없어 주저하게 되는 사람들.\n",
       "2193576                   사고가 일어난 것은 오늘 삼십 일일 오전 열시 오십분쯤.\n",
       "2193577                                     범행 시간 일분 이십초.\n",
       "2193578                             기자 지난 이십 칠일 새벽 세시반 쯤.\n",
       "2193579    기자 외계인이 복제기술로 인간을 창조했다고 믿는 종교단체의 창설자인 클로드 보리옹.\n",
       "Name: utter, Length: 1428375, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_df = no_da_n_df[no_da_n_df['noun'] == 'noun']\n",
    "n = noun_df['utter']\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          모든 거짓은 가라. 탐욕.오만.편견.절망.분단.반목.질시는 가라. 그리하여 사된 것...\n",
       "2          새로운 정신, 새로운 지식, 빛의 네트워크로 하나된 우리. 천지여, 신인류의 정수리...\n",
       "3               둥, 둥, 둥. 천년의 아침을 알리는 저 북소리. 나가라. 뛰어라. 솟아오르라.\n",
       "9                                  김대중 대통령 신년사 21세기 한민족의 시대로\n",
       "15                                     이만섭 대행 연합공천 잘못하면 다 망해\n",
       "                                 ...                        \n",
       "2193569                                            몸이 안좋으니까.\n",
       "2193570                       암튼 그래야 또 도와준 사람한테 보답도 되고 할테니까.\n",
       "2193571                         김겸원 삼성경제연구소 경기는 당연히 위축이 되겠죠.\n",
       "2193574                                 어떻게 하면 담배를 끊을 수 있을까.\n",
       "2193575    이걸 끊으면 공백이 생기고요 이 공백을 메꾸기 위한 대안이 중요한데 운동을 한다든가...\n",
       "Name: utter, Length: 765205, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_noun_df = no_da_n_df[no_da_n_df['noun'] == 'not_noun']\n",
    "not_n = not_noun_df['utter']\n",
    "not_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193580\n"
     ]
    }
   ],
   "source": [
    "print(len(n)+len(not_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = pd.DataFrame(n)\n",
    "not_n_df = pd.DataFrame(not_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>새천년 이 아침</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>지지정당 없다 69.9 본사 여론조사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>김행 전문기자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>이회창 총재 신년사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>박태준 총재 신년사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2193573</td>\n",
       "      <td>기자 담배 끊기를 결심하기에 앞서 자신이 없어 주저하게 되는 사람들.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2193576</td>\n",
       "      <td>사고가 일어난 것은 오늘 삼십 일일 오전 열시 오십분쯤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2193577</td>\n",
       "      <td>범행 시간 일분 이십초.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2193578</td>\n",
       "      <td>기자 지난 이십 칠일 새벽 세시반 쯤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2193579</td>\n",
       "      <td>기자 외계인이 복제기술로 인간을 창조했다고 믿는 종교단체의 창설자인 클로드 보리옹.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1428375 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  utter\n",
       "0                                              새천년 이 아침\n",
       "4                                  지지정당 없다 69.9 본사 여론조사\n",
       "5                                               김행 전문기자\n",
       "6                                            이회창 총재 신년사\n",
       "7                                            박태준 총재 신년사\n",
       "...                                                 ...\n",
       "2193573          기자 담배 끊기를 결심하기에 앞서 자신이 없어 주저하게 되는 사람들.\n",
       "2193576                 사고가 일어난 것은 오늘 삼십 일일 오전 열시 오십분쯤.\n",
       "2193577                                   범행 시간 일분 이십초.\n",
       "2193578                           기자 지난 이십 칠일 새벽 세시반 쯤.\n",
       "2193579  기자 외계인이 복제기술로 인간을 창조했다고 믿는 종교단체의 창설자인 클로드 보리옹.\n",
       "\n",
       "[1428375 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df.to_csv(\"./명사형.txt\", encoding='utf-8-sig', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비명사형 + ~다.\n",
    "with open('./da_list.pkl', 'rb') as f:\n",
    "    da_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_df = pd.DataFrame(da_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_df.columns = [\"utter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>한반도의 모든 산들이 어기영차 치달아 오르고, 만주벌 대륙의 산들이 쉼없이 내려와,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>새 하늘 길을 열었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>천지를 둘러싼 저 용틀임. 저 피와 땀과 눈물의 용틀임. 마침내 대지의 젖,가슴 시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>우리는 달라졌다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>우리는 깨어났다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               utter\n",
       "0  한반도의 모든 산들이 어기영차 치달아 오르고, 만주벌 대륙의 산들이 쉼없이 내려와,...\n",
       "1                                       새 하늘 길을 열었다.\n",
       "2  천지를 둘러싼 저 용틀임. 저 피와 땀과 눈물의 용틀임. 마침내 대지의 젖,가슴 시...\n",
       "3                                          우리는 달라졌다.\n",
       "4                                          우리는 깨어났다."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_df_1 = da_df[:5000000]\n",
    "da_df_2 = da_df[5000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000000\n",
      "4164402\n"
     ]
    }
   ],
   "source": [
    "print(len(da_df_1))\n",
    "print(len(da_df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9164402\n",
      "765205\n",
      "9929607\n"
     ]
    }
   ],
   "source": [
    "print(len(da_df))\n",
    "print(len(not_n_df))\n",
    "print(len(da_df)+len(not_n_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_df_1.to_csv(\"./반말(~다.)_1.txt\", encoding='utf-8-sig', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_df_2.to_csv(\"./반말(~다.)_2.txt\", encoding='utf-8-sig', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_n_df.to_csv(\"./반말(기타).txt\", encoding='utf-8-sig', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영단어 들어간 텍스트 샘플 추출\n",
    "\n",
    "txt =[]\n",
    "\n",
    "f = open(\"./스타일별 분류/under_55/script.txt\", 'r', encoding='utf-8-sig')\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    txt.append(line.strip('\\n'))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4660563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['그보다 더 큰 황금맥은 지난 수십년간 일본 민영 TV방송국들이 만들어왔던 프로그램들.',\n",
       " '소속팀의 대표지역이 다른 게 별거 이유.',\n",
       " '평소 믿고 따르던 동네 아저씨로부터 성폭행과 추행에 시달리길 구년여.',\n",
       " '책 인간동물의 공존이유 맛깔스럽게 설명',\n",
       " '4일 기준환율은 전날보다 34.50원 오른 1천4백45.10원.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(txt))\n",
    "txt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglishOrKorean(text):\n",
    "    k_count = 0\n",
    "    e_count = 0\n",
    "    for c in text:\n",
    "        if ord('가') <= ord(c) <= ord('힣'):\n",
    "            k_count+=1\n",
    "        elif ord('a') <= ord(c.lower()) <= ord('z'):\n",
    "            e_count+=1\n",
    "    return \"e\" if e_count>1 else \"k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 4660563/4660563 [00:45<00:00, 102505.91it/s]\n"
     ]
    }
   ],
   "source": [
    "k_list = []\n",
    "e_list = []\n",
    "\n",
    "for i in tqdm(txt, mininterval=1):\n",
    "    app = isEnglishOrKorean(i)\n",
    "    if app == 'k':\n",
    "        k_list.append(i)\n",
    "    else :\n",
    "        e_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205827\n"
     ]
    }
   ],
   "source": [
    "print(len(e_list))\n",
    "e_sample = e_list[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = pd.DataFrame(e_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df.to_csv(\"./eng_sample_10K.txt\", encoding='utf-8-sig', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 샘플에 인덱스 붙이기\n",
    "\n",
    "txt =[]\n",
    "\n",
    "f = open(\"./스타일별 분류/under_55/eng_sample_10K.txt\", 'r', encoding='utf-8-sig')\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    txt.append(line.strip('\\n'))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['그보다 더 큰 황금맥은 지난 수십년간 일본 민영 TV방송국들이 만들어왔던 프로그램들.',\n",
       " '정통부 50명 선발 내년부터 외국인 IT 유학생에 장학금',\n",
       " 'CBA 최고스타 숀 타버등 일급선수들 다수포함',\n",
       " '6월13일 전주 LG전 이후 10연승.',\n",
       " '토요일 토요일은 즐거워 MBC TV 저녁 7시.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(txt))\n",
    "txt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_df = pd.DataFrame(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_df['인덱스'] = txt_df.index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_df = pd.DataFrame(txt_df, columns=['인덱스',0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>인덱스</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>그보다 더 큰 황금맥은 지난 수십년간 일본 민영 TV방송국들이 만들어왔던 프로그램들.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>정통부 50명 선발 내년부터 외국인 IT 유학생에 장학금</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>CBA 최고스타 숀 타버등 일급선수들 다수포함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6월13일 전주 LG전 이후 10연승.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>토요일 토요일은 즐거워 MBC TV 저녁 7시.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   인덱스                                                0\n",
       "0    1  그보다 더 큰 황금맥은 지난 수십년간 일본 민영 TV방송국들이 만들어왔던 프로그램들.\n",
       "1    2                  정통부 50명 선발 내년부터 외국인 IT 유학생에 장학금\n",
       "2    3                        CBA 최고스타 숀 타버등 일급선수들 다수포함\n",
       "3    4                            6월13일 전주 LG전 이후 10연승.\n",
       "4    5                       토요일 토요일은 즐거워 MBC TV 저녁 7시."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_df.to_csv(\"./eng_sample_10K_2.csv\", encoding='utf-8-sig', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =[]\n",
    "\n",
    "f = open(\"./스타일별 분류/under_55/eng_sample_10K_2.txt\", 'r', encoding='utf-8-sig')\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    txt.append(line.strip('\\n'))\n",
    "f.close()\n",
    "\n",
    "# txt_df = pd.read_csv(\"./스타일별 분류/under_55/eng_sample_idx.csv\", encoding='utf-8-sig', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스만 남기고 구분자 지우기\n",
    "def idx_sep(text):\n",
    "    pattern = '(^\\d{1,5}),(\\S+)'\n",
    "    text = re.sub(pattern=pattern, repl=r'\\1 \\2', string=text)\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 172901.10it/s]\n"
     ]
    }
   ],
   "source": [
    "txt_idx = []\n",
    "\n",
    "for i in tqdm(txt, mininterval=1):\n",
    "    j = idx_sep(i)\n",
    "    txt_idx.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9996 연장 11회 김영직의 밀어내기 사구로 귀중한 결승점을 뽑은 LG의 3대2 승리.',\n",
       " '9997 환경 양측간 환경협력 강화를 위해 FTA와 별도로 약정체결방안에 대해서도 논의.',\n",
       " '9998 호남 출신은 아니지만 초등학교나 중고교를 호남에서 나왔으니 MK 포장지로 쌌다는 것.',\n",
       " '9999 LG 전자 광저우지역 제2사업자 추진 중.',\n",
       " '10000 IT 진출 지원센터 개설 인터넷 기업협회']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_idx[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_pun(text):\n",
    "    text = text.strip()\n",
    "    pattern = '(\\w)$'\n",
    "    text = re.sub(pattern=pattern, repl=r'\\1.', string=text)\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 217812.38it/s]\n"
     ]
    }
   ],
   "source": [
    "txt_fin = []\n",
    "\n",
    "for i in tqdm(txt_idx, mininterval=1):\n",
    "    j = insert_pun(i)\n",
    "    txt_fin.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9996 연장 11회 김영직의 밀어내기 사구로 귀중한 결승점을 뽑은 LG의 3대2 승리.',\n",
       " '9997 환경 양측간 환경협력 강화를 위해 FTA와 별도로 약정체결방안에 대해서도 논의.',\n",
       " '9998 호남 출신은 아니지만 초등학교나 중고교를 호남에서 나왔으니 MK 포장지로 쌌다는 것.',\n",
       " '9999 LG 전자 광저우지역 제2사업자 추진 중.',\n",
       " '10000 IT 진출 지원센터 개설 인터넷 기업협회.']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_fin[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def clean_sp(text):\n",
    "    #pattern = '[.,]'\n",
    "    #text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    #text = text.strip()\n",
    "    #text = \" \".join(text.split())\n",
    "    #return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 345503.10it/s]\n"
     ]
    }
   ],
   "source": [
    "#txt_idx2 = []\n",
    "\n",
    "#for i in tqdm(txt_idx, mininterval=1):\n",
    "    #j = clean_sp(i)\n",
    "    #txt_idx2.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 그보다 더 큰 황금맥은 지난 수십년간 일본 민영 TV방송국들이 만들어왔던 프로그램들',\n",
       " '1 정통부 50명 선발 내년부터 외국인 IT 유학생에 장학금',\n",
       " '2 CBA 최고스타 숀 타버등 일급선수들 다수포함',\n",
       " '3 6월13일 전주 LG전 이후 10연승',\n",
       " '4 토요일 토요일은 즐거워 MBC TV 저녁 7시']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#txt_idx2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_fin_df = pd.DataFrame(txt_fin)\n",
    "#txt_idx2_df = pd.DataFrame(txt_idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_fin_df.to_csv(\"./sample_10k.txt\", encoding='utf-8-sig', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =[]\n",
    "\n",
    "f = open(\"./스타일별 분류/under_55/eng_sample_euc-kr.txt\", 'r', encoding='euc-kr')\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    txt.append(line.strip('\\n'))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 지우기\n",
    "def del_idx(text):\n",
    "    pattern = '(^\\d{1,5}\\s)'\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 200301.05it/s]\n"
     ]
    }
   ],
   "source": [
    "txt_delidx = []\n",
    "\n",
    "for i in tqdm(txt, mininterval=1):\n",
    "    j = del_idx(i)\n",
    "    txt_delidx.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그보다 더 큰 황금맥은 지난 수십년간 일본 민영 TV방송국들이 만들어왔던 프로그램들',\n",
       " '정통부 50명 선발 내년부터 외국인 IT 유학생에 장학금',\n",
       " 'CBA 최고스타 숀 타버등 일급선수들 다수포함',\n",
       " '6월13일 전주 LG전 이후 10연승',\n",
       " '토요일 토요일은 즐거워 MBC TV 저녁 7시',\n",
       " 'Jaguar XK8 모델이 가드레일을 따라 달리는 모습이 보여지고 이어서 떠오르는 글자',\n",
       " '지난 주말 LG와 해태의 잠실 혈전이 대표적인 경우',\n",
       " '김한영 PD의 키스신 주문에 수줍음 많은 김원희 가 그만 새색시같은 표정을 짓고 만 것',\n",
       " '커다란 목소리가 필요한 대사는 모두 김PD의 몫',\n",
       " '하나뿐인 지구국책사업의 현주소 새만금간척사업EBS 밤945',\n",
       " 'DDR 이용료는 일반 오락실과 같은 5백원',\n",
       " '지난해 공중파 TV와 라디오 프로가 심의규정 위반으로 방송위에 적발된 사례는 7백65건',\n",
       " '23일 막오른 현대와 LG의 한국시리즈',\n",
       " 'LGEDS시스템의 인트라넷망인 이지워크',\n",
       " '녹사평역 정거장은 폭 23m에 높이 18m 길이 1백20m로 국내 최대규모',\n",
       " 'TK민정계 VS 소장파민주계 한나라 내분 대결',\n",
       " '11월25일IMF 협의단 국내 금융기관 부실상태 집중 조사',\n",
       " '깜짝 동물나라동물들의 살아남기EBS 오후520',\n",
       " '한국미국등 전자통신 12개사도 B2B망',\n",
       " '청주MBC가 제작해 22일 밤11시부터 50분간 청주지역 일대에서 방영하는 벽초 홍명희',\n",
       " 'LG강사장 가족에 편지 보내려면 내게 맡겨라',\n",
       " '로스앤젤레스에는 AM방송국이 뉴욕과 시카고를 합친 28곳보다 많은 35곳',\n",
       " 'TFTLCD 회복 조짐가격 바닥권진입 내년초 반등',\n",
       " 'LG전자 로터리 히터32만9천원 좌우회전 전기스토브 7만5천원 난방기 2백9만원',\n",
       " '152Km 직구 변화구 오키나와서 시범',\n",
       " 'RV 수출 효자자동차수출 감소에도 증가세',\n",
       " '그러나 LG 부엉이 정삼흠 만은 예외',\n",
       " '생명과학 DNA유전진화발생 등 생명 현상을 다루는 과학',\n",
       " '당신 아파트에는 in your apartment 1',\n",
       " '컴퓨터통신업체인 유니텔과 코카콜라가 광고를 교환 게재하는 것도 COOP 사례',\n",
       " '프로야구 98정규리그 OB삼성 현대롯데한화LG 쌍방울해태',\n",
       " 'MLB 김선우조진호 올림픽대표팀 합류 가능',\n",
       " 'SK그룹도 다음달로 연기된 각 계열사의 주총과 이사회를 통해 임원인사를 실시한다는 방침',\n",
       " 'YS와 인연 맺은 것을 안타깝게 생각',\n",
       " '제2세션 유라시아지역 경제통합과정에서 TSR의 역할',\n",
       " '플레이오프전만을 놓고 볼 때는 당시 MVP로 뽑힌 최창호 가 단연 으뜸',\n",
       " '한국IBM 신재철사장 올핸 e비지니스 솔루션 서비스 주력',\n",
       " '동네 사람들이 함께 모여 TV를 시청하는 것이 낯설지 않았던 그때 그 시절',\n",
       " '특히 미국 워너브라더스 사가 내놓은 TV 및 극장용 만화중 70는 코코가 만든 작품',\n",
       " '18일 오후 3시경 서울 강북구 수유동 KPA어린이댄스학원',\n",
       " 'TV드라마 맞아? MBC 고백에 시청자 비난 봇물',\n",
       " '공모방식 인수 BWCB 발행 1개월뒤 주식전환 가능',\n",
       " '미국에서 실제로 있었던 TV퀴즈쇼 비리사건을 다룬 영화',\n",
       " '최근 미국 CNN방송은 이 무렵 늘어나는 부상자를 줄이기 위한 예방법을 소개',\n",
       " '스모크 MBC TV 22일 밤 11시',\n",
       " '남편 혼자벌이로 살기가 점점 힘든 IMF 시대',\n",
       " 'GPS 단말기를 갖고 탔지만 비행기의 차단도료와 이중 창 때문에 무용지물',\n",
       " '부동산QA청약통장가입 구분은 전용면적 기준',\n",
       " '대표적인 경우가 LG와 롯데의 앙숙관계',\n",
       " '현대 투수진이 OB 삼성과 질적양적으로 달라 LG 타자들이 쉽게 공략하기 힘들다는 것',\n",
       " 'CF 이야기뉴 EF쏘나타 아름다운 동행편',\n",
       " 'LG 백화점 부천점 식품부에서 오전 12시까지 일부 품목을 싸게 판매',\n",
       " 'DJ에 고문 임명 조언하자 자네가 큰일하고 있네 칭찬',\n",
       " '작가 김수현씨 MBC상대 30억 배상 소송',\n",
       " '관련기사 현장에서캐세레스의 비극 양팀 감독의 말 연장 10회말 LG 공격',\n",
       " '김석환 풍자화 만평과 삽화전2328일 KBS 전시실',\n",
       " 'IT업체들 무료 웹제작등 불황 탈출 모색',\n",
       " '한나라당 윤석중 비서관임명은 DJ아들 비호대가',\n",
       " '1인당 청약한도는 8백주이며 발행가는 2만원 LG증권이 예상하는 주가는 5만5천원선',\n",
       " '본점은 특히 영캐주얼을 강화했으며 마르조CC클럽게스옵트 등 18개 브랜드를 취급',\n",
       " '원제 Back to the Future3 1990년작',\n",
       " '코미디뮤지컬 홍도 VS 곰순SBS 오후630',\n",
       " '연예비리 수사확대 방송관계자 SM 상당량 보유',\n",
       " '미국 UC 버클리 입학처장 서울대에 훈수',\n",
       " '9일 텍사주 어빙의 포시즌스TPC에서 열린 바이런넬슨클래식 연습경기인 프로암대회',\n",
       " '아디다스코리아컵 부천 SK와 최종전에서 01로 진 것까지 따지면 무득점 4연패',\n",
       " 'Style 패션 차분한 초콜릿 우아한 보라',\n",
       " 'FA컵은 겨울철 K리그?아마팀 모두 탈락',\n",
       " '한 원로자문회의 공약 배경DJ에 원로자문회의 의장 보장 정치보복 없다 약속 구체화',\n",
       " '사진 LG화학 클라이덴과 태평양 화이트키스의 광고장면',\n",
       " 'LG애드가 이 제도를 처음 공식 거론한 것은 지난해 10월',\n",
       " '이밖에 4위는 LG 5위 현대 6위 쌍용 7위 동양8',\n",
       " '김유택은 29일 SBS와의 경기에서 10득점 대망의 4천득점에 12점차로 다가선 것',\n",
       " 'KBS1 인간극장 5부작 2002 심청전현대판 효녀심청 재덕양 이야기',\n",
       " '연예계 비리 방송출연음반홍보 PR비 상납과 비례',\n",
       " '귀 기울이는DJ내주부터 각계인사와 열린간담회',\n",
       " '100일 MJ 대선도전 석달만에 하차 정치인생 첫 시련',\n",
       " '프로농구 9899정규리그 현대SBS SK기아',\n",
       " '원주 나래 25 29 25 21 100 SBS 32 29 22 25 108',\n",
       " 'BM협정 일방 탈퇴 30년 핵자물쇠 공식 폐기',\n",
       " '하이닉스 채권단 MOU승인본계약까지 산넘어 산',\n",
       " 'IG 퍼펙트 의료보험 거의 모든 질병 보장',\n",
       " '한국 시민사회와 소속 NGO 발전에 대한 지식인의 역할 비교',\n",
       " '그리고 영입 후 기대에 못 미치고 있는 넥센 니코스키와 LG 박현준의 목동경기!',\n",
       " 'KBS1오전10시낮12시10분 오후1시20분5시',\n",
       " '수해연금 삼성 50억SK 30억 기탁',\n",
       " '뚝섬 돔구장은 월드컵 개막전준결승전 6만석 이상의 FIFA규정에 크게 모자라는 형편',\n",
       " '국악 KBS국악관현악단 제1백2회 정기연주회 25일 오후 7시30분 KBS홀',\n",
       " '패션 판타지아동아TV 채널34 오후310',\n",
       " 'CCTV에 찍힌 남성은 28살 정 모 씨',\n",
       " 'USA TODAY 웹페이지 장쩌민 게재 실수',\n",
       " '이원복의 만화공간wwwwonbokcom만화가 이원복의 홈페이지',\n",
       " 'MBC주부가요열창대회27일 오후2시 우송예술회관 2202251',\n",
       " '도전 주부가요스타 KBS2 오전1050',\n",
       " '노무현김영삼 회동 의미노YS 정서복원 일단 성공',\n",
       " '노무현 단일후보 확정 노 TV토론서 마음비운 모습 어필',\n",
       " '그것이 알고싶다백범 암살사건 SBS TV 밤 11시',\n",
       " 'LG의 이같은 계투작전에 삼성은 4회이후 단 1안타도 못 때리는 빈공',\n",
       " 'SEM 경찰 4만명 사상 최대 경호 작전',\n",
       " '신관 2층 GV2 베 이직 7080 세일230022',\n",
       " '보사는 IBF 랭킹1위로 39승1패를 기록중',\n",
       " '가을콘서트 6인의 팝 프리마돈나KBS2 밤905',\n",
       " '정고전가 KBS 2TV 밤10시10분',\n",
       " '114대 106 SK의 8점차 승리',\n",
       " '그리고 게다가 and besides 1',\n",
       " '프랑스측에서는 KBS아나운서로 이름을 날렸던 한영난씨',\n",
       " 'CALS주경준ERP백종명설계정보화한성배',\n",
       " 'FILA컵 96국제대학올스타전 캐나다호주 한국러시아 미국일본',\n",
       " 'BEST OF BEST 가장 잊을 수 없는 순간 베스트10',\n",
       " '머니초대석 UBS 존 프레이저 아시아태평양 대표',\n",
       " 'CJ는 제일제당 의 영문이니셜을 딴 것',\n",
       " 'SBS그것이 새진행자 정진영 문성근과 다른 스타일로 승부',\n",
       " '차량통행이 다소 한가한 오후 2시쯤 LA 다운타운 근처 8번가와 노르만디가의 교차로',\n",
       " 'TV에 나오는 최신 인기 가요에 등장하는 춤을 배우는 것은 너무 쉬운 일',\n",
       " '우리 들꽃을 담은 화분 전람회 1319일 부천 LG갤러리',\n",
       " '6백달러대 스위트룸도 MA고객들도 가득찼고전체 스위트룸 판매율은 70 수준',\n",
       " '한국 시민사회의 발전과 중앙 NGO에 참여한 지식인 역할 분석',\n",
       " 'OCP는 데이터베이스 소프트웨어 전문업체인 오라클사에서 시행하는 자격 제도',\n",
       " '이번에 개발한 LAN 카드는 품질과 가격경쟁력에서 자신있는 제품',\n",
       " '돈 형편 좋아질 것 2분기 기업자금 BSI 1374',\n",
       " 'LG 생활건강이 출시한 녹스벨트는 하이드로 젤타입',\n",
       " '문희정 작가표 NO 막장! 공감과 유쾌한 웃음 100 충전!',\n",
       " '그러다 박세리의 LPGA 우승으로 분위기가 되살아났다고 자평',\n",
       " '미 반도체 TI사 하이닉스에 1억불 투자 예정',\n",
       " '박원순변호사 강단 선다이대서 NGO 조직관리 강의',\n",
       " '동 서부 LA레이커스 119103 시애틀',\n",
       " '올해 말이면 원본과 번역본을 검색할 수 있는 CD롬이 출시될 예정',\n",
       " '오 락 서세원의 화요스페셜KBS2 밤 1100',\n",
       " '그는 오는 6월말경 독일 분데스리가 FC쾰른에 입단하기로 예정돼 있는 상태',\n",
       " '대한민국 ROTC중앙회 제8대 회장 조웅기씨',\n",
       " '부천시 소사구 송내동 345 IMF 쉼터',\n",
       " 'GE캐피탈의 할부금융사 진출이 국내 금융계를 긴장시키는 이유도 이같은 전략 때문',\n",
       " 'Smile Politics 오빠동생 구청장놓고 집안싸움해운대구 내가 적임',\n",
       " '또 한화에너지 주유소는 7백79원 LG정유 주유소는 7백80원',\n",
       " '영국에선 9월 셋째주 클래식FM 금주의 앨범으로 선정',\n",
       " '기업 공정공시여부 11월 일제점검컨퍼런스콜IR도 대상',\n",
       " '에어컨 분야에선 만도 위니아가 삼성 LG 대우를 누르고 1위',\n",
       " 'Middle School English마이TV 채널44 오후 700',\n",
       " 'TV는 사랑을 싣고 KBS2 오후720',\n",
       " '쌍둥이들의 몸무게는 정상 체중에 훨씬 못미치는 308g756g 정도',\n",
       " '은화삼CC 매입은 양자간 협상이 계속 진행중',\n",
       " '월드 컬렉션동아TV 채널34 오전 1000',\n",
       " 'LG건설은 부산 서구 남부민동에 짓고 있는 주상복합건물내 아파트 96가구를 분양중',\n",
       " '이 씨의 요금제는 데이터 한도가 6기가짜리인 LTE 안심차단 요금제',\n",
       " '서울YMCA녹번복지관 청소년상담매주 월금 오전 10오후 6시3386341',\n",
       " '삼성증권배프로야구호랑이 사자 이기고 왕좌 지킬까 SK엘지롯데 탈꼴찌작전 볼거리',\n",
       " 'SLAM 순항미사일 해군 주력기인 F18에 장착될 장거리 미사일',\n",
       " '현재도 접영 2백m와 혼계영 2백m의 한국기록을 보유중',\n",
       " '원주 나래 14 30 27 20 91 SK 27 26 25 14 92',\n",
       " '김운용 IOC위원 아들 미국회사 상대 승소',\n",
       " '서울대 회의 주제는 VISIONS멀티미디어 환경에서 마케팅커뮤니케이션과 소비자와의 연계',\n",
       " '가장 눈길을 끈 핸드 헬드 PC는 스캐너가 달린 캡셰어',\n",
       " 'MTV미니시리즈 마지막 승부가 바로 그녀의 남성미 넘치는 연기가 꽃핀 곳',\n",
       " '한국 초동수사참여 강화 SOFA 개선안 사실상 합의',\n",
       " '임대 용도 ADSL모뎀 소비자 구입 가능',\n",
       " '좋은 세상만들기 HBS 채널19 밤905',\n",
       " '청계고가 STOP 대형차량 진입로에 23m제한시설 설치',\n",
       " '룩셈부르크 는 스위스 를 겨냥 OECD 회원국이 모두 따르면 우리도 하겠다는 입장',\n",
       " 'LPGA 재미동포 유니스 최로재진 공동 53위',\n",
       " '국내 인사가 터너 회장을 만날 기회는 지금까지 거의 없었다는게 KBS 의 설명',\n",
       " '7세 이상 어린이가 부모 없이 TV를 보게되는 시간 비율 95',\n",
       " 'FTA체결 필요성 공감 3 재계인사 비즈니스포럼',\n",
       " '월 2백50만원 이상은 거뜬히 벌던 S씨가 어려워지기 시작한 것도 역시 IMF 때문',\n",
       " '슈퍼리그 현대차 접전 끝에 LG화재에 역전승',\n",
       " '승용차에 타고 있던 46살 신 모 씨 등 12명이 다쳤습니다 sync 경찰',\n",
       " '지난해 4월 LG화학에서 독립법인으로 분사한 LG생활건강의 조명재 사장',\n",
       " '피시통신 하이텔 han4 천리안 zhkr1 전자우편',\n",
       " '가장 무거운 책은 Designers Dream Photoshop 7으로 38',\n",
       " '부시 외교 문제있다WPNYT무능외교비판',\n",
       " '월드컵아트모 World베컴오언 너무 좋아 여성영어 열풍',\n",
       " '제이슨 프로젝트에 동원되는 잠수정의 총길이는 23m에 높이 약 12m정도',\n",
       " '특집 연예가 중계98상반기 결산 KBS2 밤830',\n",
       " '145km속구 안타치기 이론상 불가능예일대 물리학과 교수',\n",
       " '언론김대통령 작년 수차례 충돌IPI 보고서',\n",
       " '북 핵연료봉 곧 재장전 IAEA 사찰관에 밝혀부시 대응책 고심',\n",
       " '네트워크 다큐용의 전설CTN 채널29 밤 1000',\n",
       " '시네코아4 코아아트홀 서울 동아 시네하우스 녹색 CGV강변11',\n",
       " '배구 9798슈퍼리그 LG화재경희대 삼성화재상무 고려증권현대자',\n",
       " '연일 계속되는 LA지역의 폭염으로 다저 스타디움을 찾는 관중 수가 감소',\n",
       " '청와대비서실 직제개편DJ 집안 엄정관리 의지',\n",
       " '정가 접속 DJ 행자장관 칭찬재경장관 질타와 대조',\n",
       " '나의 사랑 나의 가족KBS1 오후 735',\n",
       " '노정익 현대상선사장 MH 경영복귀 본인이 판단',\n",
       " '연세대 미 뉴욕주립대 경제학과 졸업 MIT대 슬론스쿨 경영학 석사',\n",
       " 'HOT가 뭐길래 생일파티 팬 몰려 탈진소동',\n",
       " 'LG전자도 고급형 제품을 중심으로 모델을 2030줄일 계획',\n",
       " '귤겉껍질30g 생강10g 작설5g 물6컵 꿀4큰술',\n",
       " '맞수 MSIBM 손잡았다 웹서비스 컨소시엄 공동참여',\n",
       " '행사문의 및 참가접수ICEC사무국 025683208 6339 팩스 025652434',\n",
       " 'NG밴드초청 청소년 무료콘서트8일 오후3시반 함지골청소년수련원 4145222',\n",
       " '지난해 KBS 2TV 내사랑 유미 이후 7개월만의 드라마 출연',\n",
       " '신장은 최용수 1m72보다 4 작은 1m6',\n",
       " 'IMF 쇼크 이후 국내 금융기관이 해외에서 조달한 자금 최대 규 모',\n",
       " '동산CG 대표이사 부사장 이기주 상무 김종환 배종철',\n",
       " 'SKT 라이코스 코리아 인수KT 다음과 전략적 제휴 백지화',\n",
       " 'SBS골프 1월 10일 13일 전라운드 단독 생중계!',\n",
       " '말많고 탈많은 이번 겨울 LG 의 연봉협상 테이블',\n",
       " '내일의 경기 31일 프로야구 98정규리그 OB현대 롯데LG 한화해태 쌍방울삼성',\n",
       " '외신기자 초청 오찬서 밝혀 DJ 두자식 문제가 최대 발생',\n",
       " 'LG 생활건강은 LG 화학내 2대 사업단위 중 하나로 식품 생활용품']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_delidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.DataFrame(txt_delidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.to_csv(\"./input.txt\", encoding='euc-kr', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
